{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "m5_fe and preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEfuWTHnEr-d"
      },
      "source": [
        "#**FEATURE ENGINEERING AND DATA PREPROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdiaZAKs1cZ3"
      },
      "source": [
        "###creating the final dataframe by merging all the dataframe and also performing downcasting to reduce memory consumption"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZkTJhTe1cZ3"
      },
      "source": [
        "#REFERENCE-https://www.kaggle.com/priyanka4pc/m5-model\n",
        "#code to reduce memory consumption\n",
        "import numpy as np\n",
        "def reduce_mem_usage(df, verbose=True):\n",
        "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "    start_mem = df.memory_usage().sum() / 1024**2    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)    \n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    if verbose: \n",
        "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EeKqvyu1cZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818cf506-9184-4901-bc3c-188d2eb7106c"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "calendar=pd.read_csv(\"/content/calendar.csv\")\n",
        "import datetime as dt\n",
        "calendar['date'] = calendar['date'].apply(lambda x: \n",
        "                                    dt.datetime.strptime(x,'%Y-%m-%d'))\n",
        "\n",
        "#REFERNCE-https://stackoverflow.com/questions/65842209/how-to-downcast-numeric-columns-in-pandas\n",
        "#int_columns = calendar.select_dtypes('integer').columns#selecting columns with data type int\n",
        "#calendar[int_columns] = calendar[int_columns].apply(pd.to_numeric,downcast='integer')#downcasting int64 datatype columns\n",
        "\n",
        "object_columns=calendar.select_dtypes('object').columns\n",
        "calendar[object_columns]=calendar[object_columns].astype('category')\n",
        "\n",
        "calendar=reduce_mem_usage(calendar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to  0.14 Mb (38.6% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hswVru9X1cZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302e0a73-190d-43c5-efec-06a85d64103d"
      },
      "source": [
        "price=pd.read_csv(\"/content/sell_prices.csv\")\n",
        "\n",
        "#REFERNCE-https://stackoverflow.com/questions/65842209/how-to-downcast-numeric-columns-in-pandas\n",
        "#int_columns=price.select_dtypes('integer').columns\n",
        "#price[int_columns]=price[int_columns].apply(pd.to_numeric,downcast='integer')\n",
        "\n",
        "#float_columns=price.select_dtypes('float').columns\n",
        "#price[float_columns]=price[float_columns].apply(pd.to_numeric,downcast='float')\n",
        "\n",
        "#REFERENCE-https://stackoverflow.com/questions/39092067/pandas-dataframe-convert-column-type-to-string-or-categorical\n",
        "object_columns=price.select_dtypes('object').columns\n",
        "price[object_columns]=price[object_columns].astype('category')\n",
        "\n",
        "price=reduce_mem_usage(price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 45.77 Mb (63.1% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y462r7wo1cZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f376dde-be9e-45ea-8cd5-5ecc6e8442a9"
      },
      "source": [
        "sales=pd.read_csv(\"/content/sales_train_evaluation.csv\")\n",
        "\n",
        "\n",
        "#REFERENCE-https://stackoverflow.com/questions/39092067/pandas-dataframe-convert-column-type-to-string-or-categorical\n",
        "object_columns=sales.select_dtypes('object').columns\n",
        "sales[object_columns]=sales[object_columns].astype('category')\n",
        "\n",
        "#float_columns=sales.select_dtypes('float').columns\n",
        "#sales[float_columns]=sales[float_columns].apply(pd.to_numeric,downcast='float')\n",
        "\n",
        "sales=reduce_mem_usage(sales)\n",
        "\n",
        "\n",
        "\n",
        "#dataframe is melted to put all the sales data under a single column,it will help us in plotting the time series data of sale..\n",
        "sales_melt=sales.melt(id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], var_name='d',value_name='sale')\n",
        "\n",
        "sales_melt['d']=sales_melt['d'].astype('category')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 96.55 Mb (78.7% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSdQF5Jg0dCc"
      },
      "source": [
        "#merging sales data with calendar data to plot total sales per day(in terms of date)\n",
        "sales_pivot=sales_melt.merge(calendar,on='d',how='left')\n",
        "sales_pivot.head()\n",
        "\n",
        "#converting column d to category datatype tp reduce memory consumption\n",
        "sales_pivot['d']=sales_pivot['d'].astype('category')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgW7CcQIposZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "54d4b87a-e89b-4a5f-f9c6-03834f1b4e93"
      },
      "source": [
        "final_df=sales_pivot.merge(price,on=['store_id', 'item_id', 'wm_yr_wk'],how='left')\n",
        "#REFERNCE-https://stackoverflow.com/questions/65842209/how-to-downcast-numeric-columns-in-pandas\n",
        "#int_columns = final_df.select_dtypes('integer').columns#selecting columns with data type int\n",
        "#final_df[int_columns] = final_df[int_columns].apply(pd.to_numeric,downcast='integer')#downcasting int64 datatype columns\n",
        "\n",
        "#REFERENCE-https://stackoverflow.com/questions/39092067/pandas-dataframe-convert-column-type-to-string-or-categorical\n",
        "object_columns=final_df.select_dtypes('object').columns\n",
        "final_df[object_columns]=final_df[object_columns].astype('category')\n",
        "\n",
        "#float_columns=final_df.select_dtypes('float').columns\n",
        "#final_df[float_columns]=final_df[float_columns].apply(pd.to_numeric,downcast='float')\n",
        "\n",
        "final_df=reduce_mem_usage(final_df)\n",
        "final_df.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 2485.02 Mb (0.0% reduction)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d</th>\n",
              "      <th>sale</th>\n",
              "      <th>date</th>\n",
              "      <th>wm_yr_wk</th>\n",
              "      <th>weekday</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>sell_price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_001</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_002</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_003</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_004</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
              "      <td>HOBBIES_1_005</td>\n",
              "      <td>HOBBIES_1</td>\n",
              "      <td>HOBBIES</td>\n",
              "      <td>CA_1</td>\n",
              "      <td>CA</td>\n",
              "      <td>d_1</td>\n",
              "      <td>0</td>\n",
              "      <td>2011-01-29</td>\n",
              "      <td>11101</td>\n",
              "      <td>Saturday</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id        item_id  ... snap_WI sell_price\n",
              "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  ...       0        NaN\n",
              "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  ...       0        NaN\n",
              "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  ...       0        NaN\n",
              "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  ...       0        NaN\n",
              "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  ...       0        NaN\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAt0kFNlp669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b56898-fd00-4dea-f0d8-0bd151943971"
      },
      "source": [
        "final_df.info(null_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 59181090 entries, 0 to 59181089\n",
            "Data columns (total 22 columns):\n",
            " #   Column        Non-Null Count     Dtype         \n",
            "---  ------        --------------     -----         \n",
            " 0   id            59181090 non-null  category      \n",
            " 1   item_id       59181090 non-null  category      \n",
            " 2   dept_id       59181090 non-null  category      \n",
            " 3   cat_id        59181090 non-null  category      \n",
            " 4   store_id      59181090 non-null  category      \n",
            " 5   state_id      59181090 non-null  category      \n",
            " 6   d             59181090 non-null  category      \n",
            " 7   sale          59181090 non-null  int16         \n",
            " 8   date          59181090 non-null  datetime64[ns]\n",
            " 9   wm_yr_wk      59181090 non-null  int16         \n",
            " 10  weekday       59181090 non-null  category      \n",
            " 11  wday          59181090 non-null  int8          \n",
            " 12  month         59181090 non-null  int8          \n",
            " 13  year          59181090 non-null  int16         \n",
            " 14  event_name_1  4817420 non-null   category      \n",
            " 15  event_type_1  4817420 non-null   category      \n",
            " 16  event_name_2  121960 non-null    category      \n",
            " 17  event_type_2  121960 non-null    category      \n",
            " 18  snap_CA       59181090 non-null  int8          \n",
            " 19  snap_TX       59181090 non-null  int8          \n",
            " 20  snap_WI       59181090 non-null  int8          \n",
            " 21  sell_price    46881677 non-null  float16       \n",
            "dtypes: category(12), datetime64[ns](1), float16(1), int16(3), int8(5)\n",
            "memory usage: 2.4 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIGNnx6KQFBK"
      },
      "source": [
        "##**OBSERVATION-**\n",
        "    THE COLUMNS EVENT_NAME_1,EVENT_TYPE_1,EVENT_NAME_2,EVENT_TYPE_2 AND SELL_PRICE CONTAINS NAN VALUES.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-0JIxUm2gLN"
      },
      "source": [
        "##SOME PREPROCESSING OF COLUMN 'd'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lee3U3cuNwT6"
      },
      "source": [
        "#HERE WE ARE STRIPPING THE D FROM D COLUMN AND MAKING IT INTEGER...IT WILL HELP US TO SPLIT THE DATASET USING DAY\n",
        "final_df['day'] = final_df['d'].map(lambda x: x.split('_')[1]).astype('int')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7a4lfK5_T-L"
      },
      "source": [
        "#BEFORE SPLITTING THE DATASET WE ARE REMOVING THE WEEKDAY COLUMN AS WE ALREADY HAVE WDAY COLUMN WHICH IS NUMERIC REPRESENTATION OF WEEKDAY..\n",
        "#WE ARE ALSO DROPING 'D' COLUMN SINCE WE HAVE CONVERTED IT TO A COLUMN 'DAY'\n",
        "final_df=final_df.drop(['weekday','d'],axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5HAQAJ73AbS",
        "outputId": "0f9c4d7d-4ef2-4987-a450-d10b3580073a"
      },
      "source": [
        "final_df=reduce_mem_usage(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 2428.48 Mb (12.2% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYkv1XewQeow"
      },
      "source": [
        "##**DEALING WITH THE NAN VALUES-**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTnWeAd0Q2hy"
      },
      "source": [
        "###DEALING WITH NAN VALUES IN SELL_PRICE COLUMN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g5Z5-DuRBfo",
        "outputId": "32d0dbb4-d973-4a68-e81b-442e634c652d"
      },
      "source": [
        "#out of 59181090 rows how many contains null value\n",
        "final_df['sell_price'].isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12299413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvfjHhcQRsc9"
      },
      "source": [
        "### 1ST APPROACH FOR CREATING BASELINE MODEL-\n",
        "\n",
        "    REPLACE ALL NAN VALUES WITH ZERO\n",
        "\n",
        "### 2ND APPROACH WHICH CAN BE TRIED TO IMPROVE OUR METRIC\n",
        "    THE NAN VALUES ARE DUE TO THE FACT THAT THE ITEMS ARE NOT SOLD IN THAT WEEK..SO WE CAN REPLACE THE VALUES WITH THE MEADIAN SELL_PRICE OF THAT SAME ITEMS SOLD IN DIFFERENT WEEK "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGf1Ua7adyZ6"
      },
      "source": [
        "#REFERENCE-https://stackoverflow.com/questions/19966018/pandas-filling-missing-values-by-mean-in-each-group\n",
        "#X_train['sell_price'] = X_train['sell_price'].fillna(X_train.groupby('id')['sell_price'].transform('median'))#FILLING NAN VALUES BY THE MEDIAN\n",
        "\n",
        "#X_cv['sell_price'] = X_cv['sell_price'].fillna(X_cv.groupby('id')['sell_price'].transform('median'))#FILLING NAN VALUES BY THE MEDIAN\n",
        "\n",
        "#X_test['sell_price'] = X_test['sell_price'].fillna(X_test.groupby('id')['sell_price'].transform('median'))#FILLING NAN VALUES BY THE MEDIAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBHWM9JSH-Ab"
      },
      "source": [
        "final_df['sell_price'] = final_df['sell_price'].fillna(final_df.groupby('id')['sell_price'].transform('median'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBF3Oy6JvDUx"
      },
      "source": [
        "###DEALING WITH NAN VALUES IN EVENT_NAME_1,EVENT_TYPE_1,EVENT_NAME_2,EVENT_TYPE_2 COLUMNS/ENCODING CATEGORICAL FEATURE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dmMNc11wzT1"
      },
      "source": [
        "###THE NAN VALUE IN THESE COLUMNS CAN EASILY BE DEALT BY ENCODING THE FEATURES USING LABEL ENCODINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slg1IKP37hUT"
      },
      "source": [
        "#REFERENCE-https://stackoverflow.com/questions/32011359/convert-categorical-data-in-pandas-dataframe\n",
        "#I tried using label encoder but it was giving memory error...\n",
        "#on serching found the stackoverflow article and since out categorical data are already in category dtype so we can use dataframe.cat.code to get th einteger code for each categorical value\n",
        "#for features which are not of type category will throw error,so using try except to ignore that error..\n",
        "for i in final_df.columns:\n",
        "    try:\n",
        "        final_df[i] = final_df[i].cat.codes\n",
        "    except AttributeError:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DADxLySlwTuR"
      },
      "source": [
        "##**FEATURE ENGINEERING--**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXzvguPV9S5A"
      },
      "source": [
        "##EXTRACTING SOME FEATURES USING DATETIME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX47cBId9aZL",
        "outputId": "b0ba2b5e-ad54-42e0-9d53-90e16c413efe"
      },
      "source": [
        "final_df.drop(['wm_yr_wk'],axis=1,inplace=True)\n",
        "final_df['week_of_year']=final_df['date'].dt.week"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W_BG7E2wYy6"
      },
      "source": [
        "##**1.-**1ST ENGINEERED FEATURE CAN BE A BOOLEAN FEATURE INDICATING WHETHER A DAY FALLS ON WEEKEND(1) OR WEEKDAYS(0)...THE REASON BEHIND THIS IS DURING EDA STAGE IT WAS FOUND THAT SALES ARE HIGHER ON WEEKEND THAN ON WEEKDAYS..THUS WEEKEND DOES AFFECT THE SALES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z_69gopw4i0"
      },
      "source": [
        "final_df['is_weekend']=final_df['wday'].map(lambda x:1 if x<=2 else 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFT6S1rwIzTm"
      },
      "source": [
        "##**2.**THE 2ND ENGINEERED FEATURE IS INDICATING 1 IF THE DAY IS THE 1ST DAY OF MONTH AND 2 IF THE LAST DAY OF MONTH AND 0 IF ITS NONE OF THEM....THE REASON IS BECAUSE AT EDA STAGE IT WAS FOUND OUT THAT SALES ARE HIGHER ON 1ST DAY OF MONTH AND MUCH LESS ON LAST DAY OF MONTH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w2xrlHR4e5_"
      },
      "source": [
        "month_start=final_df['date'].dt.is_month_start.map(lambda x:1 if x==True else 0)\n",
        "month_end=final_df['date'].dt.is_month_end.map(lambda x:2 if x==True else 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_7HXvU_zgMJ"
      },
      "source": [
        "final_df['is_month_start_or_end']=month_start+month_end\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5zr_HUogtyw"
      },
      "source": [
        "del month_start\n",
        "del month_end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXGcEG9CSX-L"
      },
      "source": [
        "##**3.**THE 3RD ENGINEERED FEATURE IS INDICATING 1 IF THE DAY IS THE 1ST 15 DAY OF MONTH AND 0 IF THE LAST 15 DAY OF MONTH...THE REASON IS BECAUSE AT EDA STAGE IT WAS FOUND OUT THAT SALES ARE HIGHER ON 1ST 15 DAY OF MONTH AND THE SALES DECREASES FOR LAST 15 DAYS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4fueDYBSu1b"
      },
      "source": [
        "final_df['is_first15_day_or_last15_day']=final_df['date'].dt.day.map(lambda x:1 if x<=15 else 0)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W23hq1nfp9u1"
      },
      "source": [
        "##**4.**THE 4TH ENGINEERED FEATURE THAT CAN BE TRIED IS WHETHER THE DAY IS CHRISTMAS OR NOT..THE REASON IS BECAUSE IT WAS FOUND OUT THAT AT CHRISTMAS THE SALES ARE ZERO ALL OVER THE STORES..SO IT CAN BE A USEFUL FEATURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exLEZoEF6zDj"
      },
      "source": [
        "final_df.drop(['date'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYY1Y143qZbs"
      },
      "source": [
        "final_df['is_christmas']=final_df['event_name_1'].map(lambda x:1 if x==1 else 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wic8W3gy5OK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2999327b-cebc-4a3f-a176-146109a0457a"
      },
      "source": [
        "final_df=reduce_mem_usage(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 2144.70 Mb (47.9% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiW4mHUZ9uiv"
      },
      "source": [
        "##**5.**THE 5TH ENGINEERED FEATURE WILL BE THE LAG FEATURE WHICH CONTRIBUTES THE MOST TO TIME SERIES PROBLEM.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4k6vRfGOEtT"
      },
      "source": [
        "##WE ARE TRYING WITH LAG OF 1,7,14,21,28,30 DAYS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRH1H6igOOxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92ce389-40a6-4dad-e7bf-bb4f4f8e0eb0"
      },
      "source": [
        "#REFERENCE-https://www.analyticsvidhya.com/blog/2019/12/6-powerful-feature-engineering-techniques-time-series/\n",
        "from tqdm import tqdm\n",
        "lags=[1,7,14,21,28,30,31]\n",
        "for lag in tqdm(lags):\n",
        "    final_df[\"lag_\" + str(lag)] = final_df.groupby(\"id\")[\"sale\"].shift(lag)\n",
        "    final_df[\"lag_\" + str(lag)]=final_df[\"lag_\" + str(lag)].fillna(0).astype('int')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:26<00:00,  3.80s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty_yIPf9VxTT"
      },
      "source": [
        "#filling nan values with 0 which was created due to lag features\n",
        "final_df['lag_1']=final_df['lag_1'].fillna(0).astype('int')\n",
        "final_df['lag_7']=final_df['lag_7'].fillna(0).astype('int')\n",
        "final_df['lag_14']=final_df['lag_14'].fillna(0).astype('int')\n",
        "final_df['lag_21']=final_df['lag_21'].fillna(0).astype('int')\n",
        "final_df['lag_28']=final_df['lag_28'].fillna(0).astype('int')\n",
        "final_df['lag_30']=final_df['lag_30'].fillna(0).astype('int')\n",
        "final_df['lag_31']=final_df['lag_31'].fillna(0).astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbc9OqkxPmPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c66ada-b24f-4d4f-82e0-93ce680d853c"
      },
      "source": [
        "final_df=reduce_mem_usage(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 2934.85 Mb (44.7% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PksrNahEPGys"
      },
      "source": [
        "##**6.**THE NEXT FEATURE IS THE ROLLING MEAN OF SALES WITH DIFFERENT WINDOW SIZE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfwGOL-tPVvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edf6aa2-e3d6-4459-96f5-46adac130a07"
      },
      "source": [
        "import numpy as np\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "start=datetime.now()\n",
        "temp=final_df[['id','sale']]\n",
        "def rolling_7(temp):\n",
        "      print(\"7 start\")\n",
        "      rolling_mean_7 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(7).mean())\n",
        "      rolling_mean_7.to_csv(\"rolling_mean_7\")\n",
        "      print(\"7 complete\")\n",
        "\n",
        "      \n",
        "\n",
        "def rolling_14(temp):\n",
        "      print(\"14 start\")\n",
        "      rolling_mean_14 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(14).mean())\n",
        "      rolling_mean_14.to_csv(\"rolling_mean_14\")\n",
        "      print(\"14 complete\")\n",
        "      \n",
        "     \n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "def rolling_28(temp):\n",
        "      print(\"28 start\")\n",
        "      rolling_mean_28 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(28).mean())\n",
        "      rolling_mean_28.to_csv(\"rolling_mean_28\")\n",
        "      print(\"28 complete\")\n",
        "      \n",
        "      \n",
        "\n",
        "p1 = multiprocessing.Process(target=rolling_7,args=(temp,))\n",
        "p2 = multiprocessing.Process(target=rolling_14,args=(temp,))\n",
        "p3 = multiprocessing.Process(target=rolling_28,args=(temp,))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "p3.start()\n",
        "\n",
        "\n",
        "p1.join()\n",
        "p2.join()\n",
        "p3.join()\n",
        "\n",
        "\n",
        "end=datetime.now()\n",
        "difference=end-start\n",
        "print(\"time taken\",difference)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 start\n",
            "14 start\n",
            "28 start\n",
            "7 complete\n",
            "14 complete\n",
            "28 complete\n",
            "time taken 1:02:39.128813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkmzQqOrWJ1O"
      },
      "source": [
        "import os\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdlW1dhxomZf"
      },
      "source": [
        "rolling=pd.read_csv(\"rolling_mean_28\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxSbEkBPPqxt"
      },
      "source": [
        "del rolling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqk_yRatmyLI"
      },
      "source": [
        "rolling_mean_7=pd.read_csv(\"rolling_mean_7\",)\n",
        "final_df['rolling_mean_7']=rolling_mean_7.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "\n",
        "rolling_mean_14=pd.read_csv(\"rolling_mean_14\")\n",
        "final_df['rolling_mean_14']=rolling_mean_14.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "\n",
        "\n",
        "rolling_mean_28=pd.read_csv(\"rolling_mean_28\")\n",
        "final_df['rolling_mean_28']=rolling_mean_28.drop(['Unnamed: 0'],axis=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7OPWfX1QIZe"
      },
      "source": [
        "del rolling_mean_14\n",
        "del rolling_mean_28\n",
        "del rolling_mean_7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIHMF4y8UiMx"
      },
      "source": [
        "final_df['rolling_mean_7']=final_df['rolling_mean_7'].fillna(0)\n",
        "final_df['rolling_mean_14']=final_df['rolling_mean_14'].fillna(0)\n",
        "#final_df['rolling_mean_21']=final_df['rolling_mean_21'].fillna(0)\n",
        "final_df['rolling_mean_28']=final_df['rolling_mean_28'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-tA01uGI3YH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757348a4-1953-4943-fe0e-1f58159adae3"
      },
      "source": [
        "final_df=reduce_mem_usage(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 3273.49 Mb (23.7% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buF-SJ1PsBAU"
      },
      "source": [
        "final_df.to_hdf('final_df.hdf','mydata',mode='w')\n",
        "\n",
        "#df = pd.read_hdf('my_filename.hdf','mydata')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVnONQIKWjxU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "ac636cb8-7e42-4a73-bafe-1b03e3bf2ebb"
      },
      "source": [
        "final_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>sale</th>\n",
              "      <th>wday</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>event_name_1</th>\n",
              "      <th>event_type_1</th>\n",
              "      <th>event_name_2</th>\n",
              "      <th>event_type_2</th>\n",
              "      <th>snap_CA</th>\n",
              "      <th>snap_TX</th>\n",
              "      <th>snap_WI</th>\n",
              "      <th>sell_price</th>\n",
              "      <th>day</th>\n",
              "      <th>week_of_year</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>is_month_start_or_end</th>\n",
              "      <th>is_first15_day_or_last15_day</th>\n",
              "      <th>is_christmas</th>\n",
              "      <th>lag_1</th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_14</th>\n",
              "      <th>lag_21</th>\n",
              "      <th>lag_28</th>\n",
              "      <th>lag_30</th>\n",
              "      <th>lag_31</th>\n",
              "      <th>rolling_mean_7</th>\n",
              "      <th>rolling_mean_14</th>\n",
              "      <th>rolling_mean_28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14370</td>\n",
              "      <td>1437</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.257812</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14380</td>\n",
              "      <td>1438</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.970703</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14390</td>\n",
              "      <td>1439</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.970703</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14400</td>\n",
              "      <td>1440</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.640625</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14410</td>\n",
              "      <td>1441</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2011</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.980469</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  item_id  dept_id  ...  rolling_mean_7  rolling_mean_14  rolling_mean_28\n",
              "0  14370     1437        3  ...             0.0              0.0              0.0\n",
              "1  14380     1438        3  ...             0.0              0.0              0.0\n",
              "2  14390     1439        3  ...             0.0              0.0              0.0\n",
              "3  14400     1440        3  ...             0.0              0.0              0.0\n",
              "4  14410     1441        3  ...             0.0              0.0              0.0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUdUAKUcef5H"
      },
      "source": [
        "##**7.**THE NEXT FEATURE IS THE ROLLING STANDARD DEVIATION OF SALES WITH DIFFERENT WINDOW SIZE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLl52aOJekp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c00f6c7-ebe5-4a7a-b66b-989da52f90b7"
      },
      "source": [
        "start=datetime.now()\n",
        "temp=final_df[['id','sale']]\n",
        "def rolling1_7(temp):\n",
        "      \n",
        "      rolling_std_7 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(7).std())\n",
        "      rolling_std_7.to_csv(\"rolling_std_7\")\n",
        "\n",
        "      \n",
        "\n",
        "def rolling1_14(temp):\n",
        "      rolling_std_14 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(14).std())\n",
        "      rolling_std_14.to_csv(\"rolling_std_14\")\n",
        "      \n",
        "     \n",
        "\n",
        "\n",
        "#def rolling1_21(temp):\n",
        "      #rolling_std_21 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(21).std())\n",
        "      #rolling_std_21.to_csv(\"rolling_std_21\")\n",
        "      \n",
        "      \n",
        "\n",
        "\n",
        "def rolling1_28(temp):\n",
        "      rolling_std_28 = temp.groupby(['id'])['sale'].transform(lambda x: x.rolling(28).std())\n",
        "      rolling_std_28.to_csv(\"rolling_std_28\")\n",
        "      \n",
        "      \n",
        "\n",
        "p1 = multiprocessing.Process(target=rolling1_7,args=(temp,))\n",
        "p2 = multiprocessing.Process(target=rolling1_14,args=(temp,))\n",
        "p3 = multiprocessing.Process(target=rolling1_28,args=(temp,))\n",
        "#p3 = multiprocessing.Process(target=rolling1_21,args=(temp,))\n",
        "\n",
        "\n",
        "\n",
        "p1.start()\n",
        "p2.start()\n",
        "p3.start()\n",
        "#p4.start()\n",
        "\n",
        "p1.join()\n",
        "p2.join()\n",
        "p3.join()\n",
        "#p4.join()\n",
        "\n",
        "end=datetime.now()\n",
        "difference=end-start\n",
        "print(\"time taken\",difference)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken 1:03:54.940175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F02pEWMdHcrB"
      },
      "source": [
        "rolling_std_7=pd.read_csv(\"rolling_std_7\")\n",
        "final_df['rolling_std_7']=rolling_std_7.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "rolling_std_14=pd.read_csv(\"rolling_std_14\")\n",
        "final_df['rolling_std_14']=rolling_std_14.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "#rolling_std_21=pd.read_csv(\"rolling_std_21\")\n",
        "#final_df['rolling_std_21']=rolling_std_21.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "rolling_std_28=pd.read_csv(\"rolling_std_28\")\n",
        "final_df['rolling_std_28']=rolling_std_28.drop(['Unnamed: 0'],axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7fZQdQ6faCl"
      },
      "source": [
        "del rolling_std_7\n",
        "del rolling_std_14\n",
        "del rolling_std_28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh1HUDtAakq-"
      },
      "source": [
        "final_df=final_df.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHINm28cRK4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea815af-0739-42cd-daaf-2eb07b7e29d4"
      },
      "source": [
        "final_df=reduce_mem_usage(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 3612.13 Mb (0.0% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRp3z4QUfo9B"
      },
      "source": [
        "final_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEKukvoQP_I9"
      },
      "source": [
        "##**8.**SOME FEATURE ENGINEERING FROM THE PRICE DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gF17gnAQIbB"
      },
      "source": [
        "##PREVIOUS DAY PRICE OF ITEMS(PRICE LAG WITH WINDOW 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiuogvfrQVrR"
      },
      "source": [
        "final_df[\"price_previous_day\"]=final_df['sell_price'].transform(lambda x:x.shift(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjw8ksNLR6ZR"
      },
      "source": [
        "final_df['price_previous_day']=final_df['price_previous_day'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9yebglXQu3o"
      },
      "source": [
        "##PRICE CHANGE FROM PREVIOUS DAY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRd3OcAkQzwm"
      },
      "source": [
        "diff=(final_df['price_previous_day']-final_df['sell_price'])\n",
        "deno=final_df['price_previous_day'].apply(lambda x:0.1 if x==0 else x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4txMEWY7x4e"
      },
      "source": [
        "final_df['price_change']=diff/deno"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzvRtg78SKBY"
      },
      "source": [
        "final_df['price_change']=final_df['price_change'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kExMDRvVUUJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5814f60d-1797-4673-adf9-5ec5a636b241"
      },
      "source": [
        "final_df=reduce_mem_usage(final_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mem. usage decreased to 3837.89 Mb (8.1% reduction)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VksnMtlWE6Y"
      },
      "source": [
        "##COPYING THE FINAL DATAFRAME TO GOGGLE DRIVE TO REUSE LATER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WeveuCOXPzK"
      },
      "source": [
        "final_df.to_hdf('final_df.hdf','mydata',mode='w')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ-tMLUlWKN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98881865-0c33-49dc-dfe8-31fc5a441868"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bNm_FkzWO_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f41dcc-968e-457c-d7bd-d68b40c5e9c4"
      },
      "source": [
        "!cp final_df.hdf '/content/gdrive/My Drive/m5_forecasting_data/'\n",
        "!ls -lt '/content/gdrive/My Drive/m5_forecasting_data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 3930004\n",
            "-rw------- 1 root root 4024323408 Jul  1 10:02 final_df.hdf\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}